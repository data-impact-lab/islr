---
title: "Lab 5"
author: "Hershel Mehta"
date: "March 29, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(modelr)
library(ISLR)
```

# Cross-Validation

## Validation Set Approach

First, we split our data into a training and test set.

```{r}
set.seed(1)

train_set <- sample_n(Auto, 196)
val_set <- setdiff(Auto, train_set)
```

We fit a linear model and find the RMSE on the validation set.

```{r}
lin_fit <- lm(mpg ~ horsepower, data = train_set)
modelr::rmse(lin_fit, data = val_set)
```

We fit a quadratic model and find the RMSE on the validation set.

```{r}
quad_fit <- lm(mpg ~ poly(horsepower, 2), data = train_set)
modelr::rmse(quad_fit, data = val_set)
```

We fit a cubic model and find the RMSE on the validation set.

```{r}
cubic_fit <- lm(mpg ~ poly(horsepower, 3), data = train_set)
modelr::rmse(cubic_fit, data = val_set)
```

## k-Fold Cross-Validation

First, create a tibble with the polynomial degrees you would like to test.

```{r}
poly_degrees <- tibble(
  n = 1:5
)
```

We write a function that takes a number of degrees "n_" and number of folds "k_", and does the following:

* Splits the data using k-Fold Cross-Validation (using `modelr::crossv_kfold`)
* Creates two new columns containing:
    + A polynomial model of degree "n_" fit to the training data
    + The "RMSE" of the model tested on the testing data
* Returns the mean "RMSE" across all splits

```{r}
poly_kfold <- function(n_, k_) {
  kfold_rmse <- 
    Auto %>% 
    modelr::crossv_kfold(k_) %>% 
    mutate(
      model = map(train, ~lm(mpg ~ poly(horsepower, n_), data = .)),
      rmse = map2_dbl(model, test, rmse)
    )
  
  mean(kfold_rmse$rmse)
}
```

We call the function on each of the desired polynomial degrees, to obtain the mean "RMSE" using k-Fold Cross-Validation on degree "n" with k = 10 folds.

```{r}
k <- 10

poly_degrees %>% 
  mutate(
    mean_rmse = map2_dbl(n, k, poly_kfold)
  )
```

## Leave-One-Out Cross-Validation

We note that leave-one-out cross-validation is simply k-fold validation with k = n. Therefore, we can just modify the parameters in our k-fold call!

```{r}
k <- Auto %>% nrow()

poly_degrees %>% 
  mutate(
    mean_rmse = map2_dbl(n, k, poly_kfold)
  )
```


# The Bootstrap

## Estimating the Accuracy of a Statistic of Interest

```{r}
sample_alpha <- function(x) {
  data <- as_tibble(x)
  
  X <- data$X
  Y <- data$Y
  
  (var(Y) - cov(X,Y)) / (var(X) + var(Y) - 2 * cov(X,Y))
}
```


```{r}
Portfolio %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    alpha = map_dbl(strap, sample_alpha)
  ) %>% 
  summarise(
    alpha_mean = mean(alpha),
    alpha_stddev = sd(alpha)
  )
```

## Estimating the Accuracy of a Linear Regression Model

```{r}
Auto %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    model = map(strap, ~lm(mpg ~ horsepower, data = .)),
    intercept = map_dbl(model, ~coef(.)[["(Intercept)"]]),
    slope = map_dbl(model, ~coef(.)[["horsepower"]])
  ) %>% 
  summarise(
    intercept_sd = sd(intercept),
    slope_sd = sd(slope)
  )
```



